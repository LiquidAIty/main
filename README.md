# Nx

# LiquidAIty â€” Agentic AI Core

**One backend. Multiâ€‘head frontends. Agentâ€‘0 orchestration. Department agents with tools, memory, and automation.**

This document is the canonical, developerâ€‘focused README for the current system. It covers runtime architecture, agent patterns, math & evaluation, data viz, multiâ€‘head UX, and how to extend every layer without breaking whatâ€™s working.

---

## 0) Elevator Pitch

* **Agentâ€‘0 (Supervisor)** plans â†’ fans out to department agents **in parallel** â†’ reduces to a combined answer + perâ€‘dept results.
* **Department Agents** (OpenAI dept live; others templated) each have:

  * an LLM (OpenAI or OpenRouter/DeepSeek),
  * a **toolbelt**: `mcp_call`, `n8n_call_webhook`, `memory_op`, optional `spawn_subagents`,
  * a clear persona and keywords for routing.
* **One backend** (Express + LangGraph) serves **all tools/agents** via `/api/sol/*` and `/api/tools/:id`.
* **Multiâ€‘head UI** (Lab Chat today; Builder/Reader later) talk the same contract: `POST /api/sol/run â†’ { combined, results }`.
* **Data viz** is normalized once (backend) and rendered via Plotly **or** TradingView Lightweight on the client.

---

## 1) Monorepo Layout (Nx)

```
apps/
  backend/                 # Express + LangGraph runtime
    src/
      routes/              # /api endpoints (sol/tools/debug)
      agents/              # Agentâ€‘0, factory, tools, connectors
      config/              # Sol/router configs
  client/                  # React + Vite + Tailwind (Lab head)
    src/                   # pages, app, main, styles
```

**Key contracts**

* `POST /api/sol/run` â€” Agentâ€‘0 route+execute. Input `{ q }`, output `{ ok, executed, results, combined }`.
* `POST /api/tools/:id` â€” Call a specific department agent. Body `{ prompt, provider?, n8nWebhook?, threadId? }`.
* `GET /api/sol/tools` â€” Registry listing & health.

---

## 2) Runtime Flow

```
User â†’ /api/sol/run { q }
  Agentâ€‘0.plan(q) â†’ { depts: [openai, google, ...], handoffs }
  parallel(depts.map(d => d.run(handoffs[d] || { prompt: q })))
  Agentâ€‘0.reduce(results) â†’ { combined, perDept }
  return { ok:true, executed:[...], results: perDept, combined }
```

### Department Agent (via `agentFactory`)

* Builds a LangGraph with:

  * **LLM node** (OpenAI/OpenRouter)
  * **Tools**:

    * `mcp_call(server, tool, args)` â€” MCP shim; can map to n8n webhooks or real MCP servers.
    * `n8n_call_webhook(url, payload)` â€” deterministic automations.
    * `memory_op({ op:'put|get|all', key?, value? })` â€” delegates to the existing memory tool.
    * optional `spawn_subagents(tasks:[{id,prompt}])` â€” fanned subâ€‘calls to other tools.

---

## 3) Agent Patterns (readyâ€‘toâ€‘template)

* **Planner â†’ Executor** (default Agentâ€‘0): separate planning from execution.
* **ReAct**: reason â†’ act (tool) â†’ observe â†’ repeat (bounded loops for safety).
* **Toolformer**: autonomous choice of tools when the question demands it.
* **Multiâ€‘Agent Collaboration**: roleâ€‘specialized departments with narrow scopes.
* **Memoryâ€‘Augmented**: persistent perâ€‘thread or perâ€‘agent facts (KV now; DB later).
* **Selfâ€‘Reflective**: postâ€‘hoc evaluator pass for factuality/consistency.

**Blueprint JSON (concept)**

```json
{
  "id": "planner-executor",
  "nodes": [
    { "id": "planner", "type": "planner", "model": "openai:gpt-4.1-mini" },
    { "id": "executor", "type": "tool-executor", "tools": ["openai","google","scraper"] }
  ],
  "edges": [["planner","executor"]],
  "memory": { "kind": "kv", "scope": "agent" }
}
```

---

## 4) Math & Evaluation (pragmatic & pluggable)

### Routing Score (Agentâ€‘0)

* **Keyword score**: `s_kw = matches / total_keywords`.
* **Recency boost** (if `q` mentions time): `s_rec âˆˆ {0, 0.1}`.
* **Historical success** (future): moving average success per dept.
* **Composite**: `score = 0.7*s_kw + 0.2*s_rec + 0.1*s_hist`.
* Select topâ€‘K (Kâ‰¤3) departments above threshold Ï„ (default 0.3).

### LLM Inference Hygiene

* Avoid forcing `temperature=0` on models that require default.
* For long outputs, prefer **structured schema** (JSON) + short freeâ€‘text summary.
* Use providerâ€‘specific baseURL only when needed (OpenRouter, local servers).

### Timeâ€‘Series & Trading (when enabled)

* **Signals**: SMA/EMA, ATR bands, RSI; Bayesian changeâ€‘points.
* **Risk**: max drawdown, Sharpe, hitâ€‘rate.
* **Backtest**: walkâ€‘forward; avoid leakage; report MAPE/SMAPE.

### RAG Quality (when enabled)

* Chunking: 512â€“1024 tokens; overlap 10â€“20%.
* Embeddings: cosine; topâ€‘k = 5â€“8; **MMR** optional.
* Evaluate with nDCG\@k / Recall\@k.

---

## 5) Data Visualization (normalized once)

**Backend** builds a normalized payload; **Frontend** renders with Plotly or TradingView Lightweight.

**Chart payload (example)**

```json
{
  "kind": "candles",
  "series": [
    { "name": "NVDA", "values": [{"t": 1719379200000, "o": 100, "h": 104, "l": 99, "c": 102}, ...] }
  ],
  "overlays": [
    { "type": "band", "name": "ATR", "values": [{"t": 1719379200000, "u": 105, "l": 98}, ...] }
  ],
  "annotations": [
    { "t": 1719465600000, "text": "Earnings" }
  ]
}
```

**Templates**

* Candlesticks + probability bands
* Multiâ€‘axis line (price vs. factor)
* Heatmap (sector/alpha buckets)
* Event ribbons (earnings, news, regime changes)

---

## 6) Multiâ€‘Head UI, One Backend

* **Lab Head** (now): `/lab/agent` â€” chat + perâ€‘dept panes, Mock/Live toggle.
* **Builder Head** (next): create/edit agent **blueprints**; link n8n flows; deploy.
* **Reader Head** (optional): readâ€‘only dashboards/reports.

All heads call the **same** API:

* Chat: `POST /api/sol/run { q }`.
* Admin: `POST /api/agents/*` (blueprints, instantiate, run) â€” when enabled.

**Streaming** (optional): upgrade `/sol/run` to SSE for token streaming & live tool logs.

---

## 7) n8n & MCP (no vendor lockâ€‘in)

* `mcp_call(server, tool, args)` maps to **n8n webhooks** today; later to real MCP servers.
* `n8n_call_webhook(url, payload)` triggers deterministic flows (scrape, search, pythonâ€‘exec, memory DB, etc.).
* Agents can **propose** automations (JSON spec) â†’ you approve â†’ backend creates the workflow and returns the webhook URL.

**Safety knobs**

* Only allow privileged operations (create/deploy) when a `SECURITY_TOKEN` matches.
* Log every external call with redacted payloads.

---

## 8) Developer Ergonomics (Windowsâ€‘friendly)

* **Run**

  * Backend: `npx nx serve backend`
  * Client: `npx nx run @nx/client:serve -- --open --port=5173 --strictPort`
* **Proxy**: Vite proxies `/api` â†’ `http://localhost:4000`.
* **Nx Daemon**: `npx nx daemon --start` (or set `useDaemonProcess: true`).
* **PowerShell tips**

  * Always set `$base = "http://localhost:4000/api"` before `irm`.
  * Forward Vite flags after `--` when using Nx.

---

## 9) Add a New Department Agent (1 minute)

1. Create `apps/backend/src/agents/tools/<name>.ts`:

```ts
import { createDeptAgent } from "../lang/agentFactory";
export const googleTool = createDeptAgent({
  id: "google",
  name: "Google Search",
  defaultPersona: [
    "You are the Search Department.",
    "Use mcp_call(server:'n8n', tool:'workflow.run', args:{ name:'search', query:'...' }).",
    "Or n8n_call_webhook(url:'/webhook/search', payload:{ query:'...' }).",
    "Store quick facts with memory_op put/get. Be concise, cite sources briefly."
  ].join("\n"),
  matchKeywords: ["google","search","news","web","query"]
});
```

2. Register in `registry.ts` (add to `TOOL_LIST`).
3. Smoke test:

```pwsh
$base = "http://localhost:4000/api"
$b = @{ prompt = "latest on NVDA; cite 3 sources" } | ConvertTo-Json
irm "$base/tools/google" -Method POST -ContentType "application/json" -Body $b
```

---

## ðŸŽ¯ Boss Agent - AI Orchestrator

The Boss Agent is a sophisticated AI orchestrator that coordinates multiple specialized agents to complete complex tasks. It acts as the central hub for AI task delegation and management.

### Features
- **Multi-agent coordination**: Delegates tasks to specialized agents (OpenAI, Kimi, n8n workflows)
- **Knowledge graph integration**: Builds and queries knowledge graphs for context
- **Workflow automation**: Triggers n8n workflows for complex processes
- **Real-time chat interface**: Interactive web-based UI for task management

### Quick Start

1. **Start the backend** (runs on port 4000):
   ```bash
   nx serve backend
   ```

2. **Start the frontend** (runs on port 5173):
   ```bash
   nx serve client
   ```

3. **Access the Boss Agent**:
   - Navigate to `http://localhost:5173/boss-agent`
   - Or from Agent Manager â†’ click "ðŸŽ¯ Boss Agent" button

### Usage

1. **Basic Task Delegation**:
   - Type your task in the chat interface
   - The Boss Agent will analyze and delegate to appropriate specialized agents
   - Results are aggregated and returned in real-time

2. **Example Tasks**:
   - "Create a marketing campaign for a new AI product"
   - "Research the latest trends in machine learning"
   - "Generate code for a data processing pipeline"
   - "Build a knowledge graph from YouTube videos about AI"

### Environment Variables

Required for full functionality:

```bash
# OpenAI Configuration
OPENAI_API_KEY=your_openai_key_here
OPENAI_MODEL=gpt-4-turbo-preview

# OpenRouter Configuration (for Kimi, DeepSeek, etc.)
OPENROUTER_API_KEY=your_openrouter_key_here
OPENROUTER_MODEL=kimi/k1

# n8n Configuration
N8N_BASE_URL=http://localhost:5678

# Optional: Database for knowledge graphs
DATABASE_URL=postgresql://user:pass@localhost:5432/liquidaity
```

### Architecture

The Boss Agent follows a three-step orchestration process:

1. **Plan**: Analyzes the task and creates a delegation strategy
2. **Act**: Executes tasks across specialized agents
3. **Finalize**: Aggregates results and provides comprehensive response

### API Endpoints

- `POST /api/agent/boss` - Main orchestrator endpoint
- `POST /api/sol/run` - Legacy agent runner (still supported)
- `GET /health` - Backend health check

### Integration with Agent Manager

The Boss Agent is fully integrated with the Agent Manager:
- Use the "ðŸŽ¯ Boss Agent" button in Agent Manager for quick access
- Share context between Agent Manager and Boss Agent
- Unified interface for all AI operations

---

## 10) Prompts (dropâ€‘ins)

**Agentâ€‘0 (router/supervisor)**

```
You are Agentâ€‘0. Plan briefly, then select up to 3 departments to run in parallel.
Return JSON: { plan, chosen_departments: string[], handoffs: { [id]: any } }.
Do not make up tools. Prefer departments whose keywords match the query intent.
```

**Department template**

```
You are the {department_name} department.
Tools: mcp_call, n8n_call_webhook, memory_op, (optional) spawn_subagents.
Follow Agentâ€‘0 plan. If unclear, ask one clarification question.
Return JSON: { summary, evidence?: any[], next?: string[] }.
```

**MCP autobuilder (to draft blueprints)**

```
Draft a LangGraph blueprint JSON for pattern "{pattern}" using tools {tools}.
Include nodes (with ids/types), edges, and minimal system prompts per node.
Assume model "{model}". Return JSON only.
```

---

## 11) Roadmap (conservative + powerful)

* **Blueprint store**: save/load agent graphs; versioned.
* **Graph trace viewer**: visualize plan â†’ parallel runs â†’ reduction.
* **Streaming & tool logs**: SSE with partials and perâ€‘dept spans.
* **RAG + vector DB**: add embeddings, citations, evaluation.
* **Trading & research agents**: connectors, backtests, risk dashboards.
* **Multiâ€‘tenant**: perâ€‘tenant registries, usage metering, role guards.

---

## 12) Ops & Security

* Do not log secrets. Only log **presence** booleans for env.
* Rate limit external calls; add exponential backoff for flaky providers.
* Add `/metrics` (p50/p95 latency per tool; success/error counters).
* Optional: audit log middleware â†’ DB (tool, duration, status, redacted args).

---

## 13) Quick Troubleshooting

* **5173 404** â†’ missing `apps/client/index.html` or wrong entry import.
* **Invalid URI in PowerShell** â†’ forgot `$base`.
* **OpenAI 400 (temperature)** â†’ donâ€™t override temperature on models that forbid it.
* **Provider 401** â†’ wrong key or wrong baseURL; set `configuration.baseURL` for OpenRouter.
* **/sol/tools missing agent** â†’ not added to `TOOL_LIST` or file unsaved.

---

### You now have: one backend, many agents, multiple heads â€”

**and a clean path to an Agent Builder without tearing up the core.**


<a alt="Nx logo" href="https://nx.dev" target="_blank" rel="noreferrer"><img src="https://raw.githubusercontent.com/nrwl/nx/master/images/nx-logo.png" width="45"></a>

âœ¨ Your new, shiny [Nx workspace](https://nx.dev) is ready âœ¨.

[Learn more about this workspace setup and its capabilities](https://nx.dev/nx-api/node?utm_source=nx_project&amp;utm_medium=readme&amp;utm_campaign=nx_projects) or run `npx nx graph` to visually explore what was created. Now, let's get you up to speed!

## Run tasks

To run the dev server for your app, use:

```sh
npx nx serve backend
```

To create a production bundle:

```sh
npx nx build backend
```

To see all available targets to run for a project, run:

```sh
npx nx show project backend
```

These targets are either [inferred automatically](https://nx.dev/concepts/inferred-tasks?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects) or defined in the `project.json` or `package.json` files.

[More about running tasks in the docs &raquo;](https://nx.dev/features/run-tasks?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)

## Add new projects

While you could add new projects to your workspace manually, you might want to leverage [Nx plugins](https://nx.dev/concepts/nx-plugins?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects) and their [code generation](https://nx.dev/features/generate-code?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects) feature.

Use the plugin's generator to create new projects.

To generate a new application, use:

```sh
npx nx g @nx/node:app demo
```

To generate a new library, use:

```sh
npx nx g @nx/node:lib mylib
```

You can use `npx nx list` to get a list of installed plugins. Then, run `npx nx list <plugin-name>` to learn about more specific capabilities of a particular plugin. Alternatively, [install Nx Console](https://nx.dev/getting-started/editor-setup?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects) to browse plugins and generators in your IDE.

[Learn more about Nx plugins &raquo;](https://nx.dev/concepts/nx-plugins?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects) | [Browse the plugin registry &raquo;](https://nx.dev/plugin-registry?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)

## Set up CI!

### Step 1

To connect to Nx Cloud, run the following command:

```sh
npx nx connect
```

Connecting to Nx Cloud ensures a [fast and scalable CI](https://nx.dev/ci/intro/why-nx-cloud?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects) pipeline. It includes features such as:

- [Remote caching](https://nx.dev/ci/features/remote-cache?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)
- [Task distribution across multiple machines](https://nx.dev/ci/features/distribute-task-execution?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)
- [Automated e2e test splitting](https://nx.dev/ci/features/split-e2e-tasks?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)
- [Task flakiness detection and rerunning](https://nx.dev/ci/features/flaky-tasks?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)

### Step 2

Use the following command to configure a CI workflow for your workspace:

```sh
npx nx g ci-workflow
```

[Learn more about Nx on CI](https://nx.dev/ci/intro/ci-with-nx#ready-get-started-with-your-provider?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)

## Install Nx Console

Nx Console is an editor extension that enriches your developer experience. It lets you run tasks, generate code, and improves code autocompletion in your IDE. It is available for VSCode and IntelliJ.

[Install Nx Console &raquo;](https://nx.dev/getting-started/editor-setup?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)

## Useful links

Learn more:

- [Learn more about this workspace setup](https://nx.dev/nx-api/node?utm_source=nx_project&amp;utm_medium=readme&amp;utm_campaign=nx_projects)
- [Learn about Nx on CI](https://nx.dev/ci/intro/ci-with-nx?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)
- [Releasing Packages with Nx release](https://nx.dev/features/manage-releases?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)
- [What are Nx plugins?](https://nx.dev/concepts/nx-plugins?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)

And join the Nx community:
- [Discord](https://go.nx.dev/community)
- [Follow us on X](https://twitter.com/nxdevtools) or [LinkedIn](https://www.linkedin.com/company/nrwl)
- [Our Youtube channel](https://www.youtube.com/@nxdevtools)
- [Our blog](https://nx.dev/blog?utm_source=nx_project&utm_medium=readme&utm_campaign=nx_projects)
